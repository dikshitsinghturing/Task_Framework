{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def plot_workflow(graph_data):\n",
    "    \"\"\"\n",
    "    Renders a directed workflow graph from a dict of nodes & edges using Graphviz.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1) Create the Digraph and set global attrs\n",
    "    dot = Digraph(\n",
    "        name='workflow',\n",
    "        format='png',\n",
    "        engine='dot'\n",
    "    )\n",
    "    dot.attr(\n",
    "        splines='true',       # smooth curved edges\n",
    "        overlap='false',      # try to avoid any overlaps\n",
    "        rankdir='TB',         # Top → Bottom flow\n",
    "        nodesep='0.6',        # separation between nodes\n",
    "        ranksep='1.5'         # separation between ranks/layers\n",
    "    )\n",
    "    \n",
    "    # 2) Default node style\n",
    "    dot.attr('node',\n",
    "        shape='box',\n",
    "        style='rounded,filled',\n",
    "        fontname='Helvetica',\n",
    "        fontsize='12',\n",
    "        color='navy'\n",
    "    )\n",
    "    \n",
    "    # 3) Add nodes\n",
    "    for node_id, node_info in graph_data['nodes'].items():\n",
    "        label = node_info.get('name', node_id)\n",
    "        \n",
    "        # highlight the root instruction node in green\n",
    "        if label == 'instruction':\n",
    "            fillcolor = 'lightgreen'\n",
    "            border_color = 'darkgreen'\n",
    "        else:\n",
    "            fillcolor = 'lightblue'\n",
    "            border_color = 'navy'\n",
    "        \n",
    "        dot.node(\n",
    "            node_id,\n",
    "            label=label,\n",
    "            fillcolor=fillcolor,\n",
    "            color=border_color\n",
    "        )\n",
    "    \n",
    "    # 4) Add edges (with labels)\n",
    "    for e in graph_data['edges']:\n",
    "        src, dst = e['from'], e['to']\n",
    "        lbl = e.get('label', '')\n",
    "        dot.edge(src, dst, label=lbl, color='blue')\n",
    "\n",
    "    return dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def detect_spec_version(spec):\n",
    "    \"\"\"\n",
    "    Returns 'old' if no action has an 'id' key AND no edge.connection\n",
    "    has 'from_id' or 'to_id'. Otherwise returns 'new'.\n",
    "    \"\"\"\n",
    "    task = spec.get(\"task\", {})\n",
    "    actions = task.get(\"actions\", [])\n",
    "    edges   = task.get(\"edges\", [])\n",
    "\n",
    "    # Check for any action.id\n",
    "    has_action_id = any(\"id\" in act for act in actions)\n",
    "\n",
    "    # Check for any from_id/to_id in edge.connection\n",
    "    has_edge_ids = any(\n",
    "        (\"from_id\" in edge.get(\"connection\", {})) or\n",
    "        (\"to_id\"   in edge.get(\"connection\", {}))\n",
    "        for edge in edges\n",
    "    )\n",
    "\n",
    "    return \"new\" if (has_action_id or has_edge_ids) else \"old\"\n",
    "\n",
    "def ensure_list(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        return [p.strip() for p in x.split(\",\")]\n",
    "    return [x]\n",
    "\n",
    "def assign_ids_to_actions(spec):\n",
    "    \"\"\"\n",
    "    Assigns an 'id' to each action only if not already present.\n",
    "    Existing 'id's are honored, and counts are bumped accordingly.\n",
    "    \"\"\"\n",
    "    # First gather max assigned id per name\n",
    "    max_id = defaultdict(lambda: -1)\n",
    "    for act in spec[\"task\"][\"actions\"]:\n",
    "        if \"id\" in act:\n",
    "            name = act[\"name\"]\n",
    "            max_id[name] = max(max_id[name], act[\"id\"])\n",
    "\n",
    "    # Now assign missing ids\n",
    "    next_id = { name: max_id[name] + 1 for name in max_id }\n",
    "    for act in spec[\"task\"][\"actions\"]:\n",
    "        name = act[\"name\"]\n",
    "        if \"id\" not in act:\n",
    "            # if we haven't seen this name at all, next_id[name] will default to 0\n",
    "            act[\"id\"] = next_id.setdefault(name, 0)\n",
    "            next_id[name] += 1\n",
    "\n",
    "    return spec\n",
    "\n",
    "def assign_ids_to_edges(spec):\n",
    "    \"\"\"\n",
    "    Assigns 'from_id' and 'to_id' on each edge only if not provided.\n",
    "    If provided, consumes arguments/outputs from the matching instance.\n",
    "    \"\"\"\n",
    "    actions = spec[\"task\"][\"actions\"]\n",
    "    edges   = spec[\"task\"][\"edges\"]\n",
    "\n",
    "    # Collect all names mentioned\n",
    "    action_names = { act[\"name\"] for act in actions }\n",
    "    edge_from    = { e[\"from\"] for e in edges }\n",
    "    edge_to      = { e[\"to\"]   for e in edges }\n",
    "    all_names    = action_names | edge_from | edge_to\n",
    "\n",
    "    # Build per-instance input-argument trackers\n",
    "    input_instances = defaultdict(list)\n",
    "    for act in actions:\n",
    "        name, aid = act[\"name\"], act[\"id\"]\n",
    "        args = set(act[\"arguments\"].keys())\n",
    "        input_instances[name].append({\"id\": aid, \"args_left\": set(args)})\n",
    "    # Ensure every name has at least one instance\n",
    "    for name in all_names:\n",
    "        if name not in input_instances:\n",
    "            input_instances[name].append({\"id\": 0, \"args_left\": set()})\n",
    "    # Sort by id\n",
    "    for name in input_instances:\n",
    "        input_instances[name].sort(key=lambda x: x[\"id\"])\n",
    "\n",
    "    # Build per-instance output trackers\n",
    "    output_keys = defaultdict(set)\n",
    "    for e in edges:\n",
    "        frm  = e[\"from\"]\n",
    "        outs = ensure_list(e[\"connection\"].get(\"output\", []))\n",
    "        output_keys[frm].update(outs)\n",
    "\n",
    "    output_instances = defaultdict(list)\n",
    "    for name, insts in input_instances.items():\n",
    "        keys = output_keys.get(name, set())\n",
    "        for inst in insts:\n",
    "            output_instances[name].append({\n",
    "                \"id\": inst[\"id\"],\n",
    "                \"outs_left\": set(keys)\n",
    "            })\n",
    "        output_instances[name].sort(key=lambda x: x[\"id\"])\n",
    "\n",
    "    # Now fill in edge ids, consuming from instances\n",
    "    for e in edges:\n",
    "        frm, to = e[\"from\"], e[\"to\"]\n",
    "        conn     = e[\"connection\"]\n",
    "        need_out = set(ensure_list(conn.get(\"output\", [])))\n",
    "        need_in  = set(ensure_list(conn.get(\"input\",  [])))\n",
    "\n",
    "        # FROM_ID\n",
    "        if \"from_id\" in conn:\n",
    "            # honor provided from_id\n",
    "            provided = conn[\"from_id\"]\n",
    "            inst = next((i for i in output_instances[frm] if i[\"id\"] == provided), None)\n",
    "            if inst is None:\n",
    "                raise ValueError(f\"Edge {e}: invalid from_id={provided} for action '{frm}'\")\n",
    "            inst[\"outs_left\"] -= need_out\n",
    "        else:\n",
    "            # assign the earliest instance that still has these outputs\n",
    "            for inst in output_instances[frm]:\n",
    "                if inst[\"outs_left\"] & need_out:\n",
    "                    conn[\"from_id\"]     = inst[\"id\"]\n",
    "                    inst[\"outs_left\"]  -= need_out\n",
    "                    break\n",
    "            else:\n",
    "                # fallback to last instance\n",
    "                conn[\"from_id\"] = output_instances[frm][-1][\"id\"]\n",
    "\n",
    "        # TO_ID\n",
    "        if \"to_id\" in conn:\n",
    "            provided = conn[\"to_id\"]\n",
    "            inst = next((i for i in input_instances[to] if i[\"id\"] == provided), None)\n",
    "            if inst is None:\n",
    "                raise ValueError(f\"Edge {e}: invalid to_id={provided} for action '{to}'\")\n",
    "            inst[\"args_left\"] -= need_in\n",
    "        else:\n",
    "            for inst in input_instances[to]:\n",
    "                if inst[\"args_left\"] & need_in:\n",
    "                    conn[\"to_id\"]      = inst[\"id\"]\n",
    "                    inst[\"args_left\"] -= need_in\n",
    "                    break\n",
    "            else:\n",
    "                conn[\"to_id\"] = input_instances[to][-1][\"id\"]\n",
    "\n",
    "    return spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict, deque\n",
    "from IPython.display import display\n",
    "\n",
    "def merge_dicts(d1, d2):\n",
    "    \"\"\"Merge two dicts, error on key collision.\"\"\"\n",
    "    overlap = set(d1) & set(d2)\n",
    "    if overlap:\n",
    "        raise ValueError(f\"Colliding keys: {overlap}\")\n",
    "    new = d1.copy()\n",
    "    new.update(d2)\n",
    "    return new\n",
    "\n",
    "def ensure_list(x):\n",
    "    \"\"\"Normalize to a list of strings.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        return [p.strip() for p in x.split(\",\")]\n",
    "    return [x]\n",
    "\n",
    "def validate_task_and_build_graph_data(json_path):\n",
    "    \"\"\"\n",
    "    Loads your task.json, applies versioning logic, simulates the BFS data-flow,\n",
    "    and returns a dict with just:\n",
    "      - 'nodes': { node_key: { 'name':…, 'arguments':… } }\n",
    "      - 'edges': [ { 'from':u, 'to':v, 'output':[…], 'input':[…], 'label':… }, … ]\n",
    "    \"\"\"\n",
    "    with open(json_path) as f:\n",
    "        spec = json.load(f)\n",
    "\n",
    "    version = detect_spec_version(spec)\n",
    "    print(f\"Detected spec version: {version}\")\n",
    "\n",
    "    if version == \"old\":\n",
    "        spec = assign_ids_to_actions(spec)\n",
    "        spec = assign_ids_to_edges(spec)\n",
    "    else:\n",
    "        print(\"Spec already contains ids; skipping version change.\")\n",
    "\n",
    "    task        = spec[\"task\"]\n",
    "    actions     = task[\"actions\"]\n",
    "    edges_input = task[\"edges\"]\n",
    "\n",
    "    # build function info with duplicate-node ids in the name\n",
    "    function_info = {}\n",
    "    for act in actions:\n",
    "        act_id = act.get(\"id\", 0)\n",
    "        base  = act[\"name\"]\n",
    "        name  = f\"{base} ({act_id})\" if act_id != 0 else base\n",
    "        key   = f\"{base}_{act_id}\"\n",
    "        if key in function_info:\n",
    "            raise ValueError(\n",
    "                f\"Action with same ID already exists: '{key}'\"\n",
    "            )\n",
    "        function_info[key] = {\n",
    "            \"name\":      name,\n",
    "            \"arguments\": act[\"arguments\"].copy(),\n",
    "            \"args_left\": len(act[\"arguments\"]),\n",
    "            \"outputs\": act.get(\"outputs\", {}),\n",
    "            \"received\":  {}\n",
    "        }\n",
    "    # pseudo-root\n",
    "    function_info[\"instruction_0\"] = {\n",
    "        \"name\":      \"instruction\",\n",
    "        \"arguments\": {},\n",
    "        \"args_left\": 0,\n",
    "        \"received\":  {}\n",
    "    }\n",
    "\n",
    "    # build adjacency\n",
    "    function_connections = defaultdict(list)\n",
    "    for edge in edges_input:\n",
    "        c   = edge[\"connection\"]\n",
    "        src = f\"{edge['from']}_{c.get('from_id', 0)}\"\n",
    "        tgt = f\"{edge['to']}_{c.get('to_id',   0)}\"\n",
    "        outs = ensure_list(c.get(\"output\", []))\n",
    "        ins  = ensure_list(c.get(\"input\",  []))\n",
    "        if len(outs) != len(ins):\n",
    "            raise ValueError(\n",
    "                f\"Edge's input and output length do not match:\\n\"\n",
    "                f\"Source: {src}\\n\"\n",
    "                f\"Target: {tgt}\\n\"\n",
    "                f\"Ouputs: {outs}\\n\"\n",
    "                f\"Inputs: {ins}\\n\"\n",
    "            )\n",
    "        function_connections[src].append({\n",
    "            \"to\":     tgt,\n",
    "            \"output\": outs,\n",
    "            \"input\":  ins\n",
    "        })\n",
    "\n",
    "    # BFS simulation\n",
    "    queue      = deque([(\"instruction_0\", 0)])\n",
    "    visited    = {\"instruction_0\"}\n",
    "    nodes_dict = {}\n",
    "    edges_list = []\n",
    "    levels     = {}\n",
    "\n",
    "    while queue:\n",
    "        src, lvl = queue.popleft()\n",
    "        levels[src] = lvl\n",
    "        info = function_info[src]\n",
    "        fn   = info[\"name\"]\n",
    "        args_dict     = info[\"arguments\"]\n",
    "        received_args = info[\"received\"]\n",
    "\n",
    "        if fn != \"instruction\":\n",
    "            if set(received_args.keys()) != set(args_dict.keys()):\n",
    "                print(json.dumps({\n",
    "                    \"function\": src,\n",
    "                    \"expected_args\": list(args_dict.keys()),\n",
    "                    \"received_args\": list(received_args.keys())\n",
    "                }, indent=2))\n",
    "                raise ValueError(f\"Arg mismatch at {src}: \"\n",
    "                                 f\"expected {list(args_dict.keys())}, \"\n",
    "                                 f\"got {list(received_args.keys())}\")\n",
    "            print(f\"{fn} ({', '.join(args_dict.keys())})\")\n",
    "            \n",
    "        # record node\n",
    "        nodes_dict[src] = {\n",
    "            \"name\":      fn,\n",
    "            \"arguments\": args_dict\n",
    "        }\n",
    "\n",
    "        # edges out\n",
    "        for link in function_connections[src]:\n",
    "            tgt     = link[\"to\"]\n",
    "            outputs = link[\"output\"]\n",
    "            inputs  = link[\"input\"]\n",
    "            label   = f\"{', '.join(outputs)} → {', '.join(inputs)}\"\n",
    "\n",
    "            edges_list.append({\n",
    "                \"from\":   src,\n",
    "                \"to\":     tgt,\n",
    "                \"output\": outputs,\n",
    "                \"input\":  inputs,\n",
    "                \"label\":  label\n",
    "            })\n",
    "\n",
    "            args_map = dict(zip(inputs, outputs))\n",
    "            try:\n",
    "                function_info[tgt][\"received\"] = merge_dicts(\n",
    "                    function_info[tgt][\"received\"], args_map\n",
    "                )\n",
    "            except ValueError as e:\n",
    "                print(f\"Merge conflict on edge {src} → {tgt}: mapping={args_map}, existing={function_info[tgt]['received']}\")\n",
    "                raise ValueError(f\"Argument merge conflict at edge {src}→{tgt}\") from e\n",
    "\n",
    "            function_info[tgt][\"args_left\"] -= len(outputs)\n",
    "            if function_info[tgt][\"args_left\"] < 0:\n",
    "                print(f\"Too many arguments received for {tgt}. Please check the edges.\")\n",
    "            if function_info[tgt][\"args_left\"] == 0 and tgt not in visited:\n",
    "                visited.add(tgt)\n",
    "                queue.append((tgt, lvl + 1))\n",
    "            \n",
    "\n",
    "    # edge count check\n",
    "    actual   = len(edges_list)\n",
    "    expected = task.get(\"num_edges\", actual)\n",
    "    if actual != expected:\n",
    "        print(f\"Edge list: {edges_list}\")\n",
    "        raise ValueError(f\"Edge count mismatch: expected {expected}, got {actual}\")\n",
    "    \n",
    "    # verify no actions were left unaccessed by the BFS\n",
    "    for act in task[\"actions\"]:\n",
    "        key = f\"{act['name']}_{act.get('id', 0)}\"\n",
    "        if key not in levels:\n",
    "            print(function_info[key][\"received\"])\n",
    "            raise ValueError(f\"Action {key} was never reached in BFS.\")\n",
    "\n",
    "    # verify that each edge's source action appears before its target action in the original list\n",
    "    action_positions = {\n",
    "        f\"{act['name']}_{act.get('id', 0)}\": idx\n",
    "        for idx, act in enumerate(actions)\n",
    "    }\n",
    "\n",
    "    for edge in edges_list:\n",
    "        src, tgt = edge['from'], edge['to']\n",
    "        # skip the pseudo-root, which isn't in actions\n",
    "        if src == \"instruction_0\":\n",
    "            continue\n",
    "        # if either endpoint isn’t actually an action (just in case), skip\n",
    "        if src not in action_positions or tgt not in action_positions:\n",
    "            continue\n",
    "        if action_positions[src] >= action_positions[tgt]:\n",
    "            raise ValueError(\n",
    "                f\"Action order violation: '{src}' (pos {action_positions[src]}) \"\n",
    "                f\"must come before '{tgt}' (pos {action_positions[tgt]})\"\n",
    "            )\n",
    "\n",
    "    return {\"nodes\": nodes_dict, \"edges\": edges_list}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    task_path = \"./test.json\"\n",
    "    graph_data = validate_task_and_build_graph_data(task_path)\n",
    "    dot = plot_workflow(graph_data)\n",
    "    display(dot)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
